{"name":"Libdnn","tagline":"C++ Library of Deep Neural Network","body":"libdnn\r\n======\r\n\r\nC++ Library of Deep Neural Network\r\n\r\n# Prerequisite\r\nYou need\r\n- A Graphic Processing Unit (GPU)\r\n- Linux / Ubuntu\r\n- Install [NVIDIA CUDA toolkit](https://developer.nvidia.com/cuda-toolkit) (at least CUDA 5.0)\r\n\r\n# Quick Start\r\n1. ```git clone https://github.com/botonchou/libdnn.git && cd libdnn && ./install-sh```\r\n2. ```cd example/```\r\n3. ```dnn-init data/a1a --nodes 512-512``` ( Please enter 2 )\r\n4. ```dnn-train data/a1a --pre 2 -f a1a.model --min-acc 0.8```\r\n5. ```dnn-predict data/a1a.t a1a.model```\r\n\r\n# Examples\r\nThere're 3 examples in example/:\r\n- example1.sh\r\n- example2.sh\r\n- example3.sh\r\n\r\nYou can run all of them by ```./go_all.sh```\r\n\r\n# How to Install ?\r\n```bash\r\ngit clone https://github.com/botonchou/libdnn.git\r\ncd libdnn/\r\n./install-sh\r\n```\r\n\r\n# Tutorial\r\n\r\nLibdnn aims to an easy quick machine learning using **deep neural network**.\r\n\r\n### Prepare your data\r\n\r\n#### Training data and testing data\r\n\r\nYou need at least two data files, one with labels (called training data) and the other with/without labels (called testing data.)\r\n\r\nIf you just want to mess around but without data at hand, you can download some from the [LibSVM website](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/). \r\n\r\n#### Data Format\r\nThe data can be provided either in the LIBSVM format or the dense format.\r\n\r\n##### LIBSVM format:\r\n```\r\n-1 5:1 6:1 15:1 22:1 36:1 42:1\r\n+1 3:1 6:1 17:1 19:1 39:1 42:1\r\n-1 5:1 7:1 14:1 22:1 36:1 40:1\r\n-1 1:1 6:1 17:1 22:1 36:1 42:1\r\n+1 4:1 6:1 14:1 29:1 39:1 42:1\r\n-1 3:1 6:1 15:1 22:1 36:1 42:1\r\n+1 5:1 6:1 15:1 22:1 36:1 40:1\r\n```\r\n\r\nEach row is one feature vector. In this case, 7 rows means 7 feature vector (i.e. 7 training data.)\r\nThe first column of each row are the labels, and the rest are feature vectors in the sparse format. Take the first row for example:\r\n```\r\n-1 5:1 6:1 15:1 22:1 36:1 42:1\r\n```\r\n**-1** is the label. The n:x format means the value of n-th dimension of this vector is x. In this example, it's a vector consists most of 0 with only few exceptions at 5, 6, 15, 22, 36, 42.\r\n\r\n##### Dense format:\r\n\r\n```\r\n-1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\r\n+1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\r\n-1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\r\n-1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\r\n+1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1\r\n-1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\r\n+1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0\r\n```\r\n(this is the same data as the above)\r\n\r\n## How to Use ?\r\nThere're 3 programs, dnn-init, dnn-train, dnn-predict.\r\n\r\n### dnn-init\r\n```\r\ndnn-init [options] training_data [model_out]\r\n```\r\nThis program performs a model initialization using stacked Restricted Boltzmann Machine (stacked RBM). For example:\r\n```\r\ndnn-init --nodes 1024-1024 train.dat\r\n```\r\nThe program will first ask you for the number of target classes (i.e. the number of nodes in output layer, **Dout**). Also, it'll found the dimension of input feature vector (**Din**) from *train.dat*. \r\nIt then perform stacked RBM initialization for a neural network of the structure:\r\n```\r\nDin-1024-1024-Dout\r\n```\r\n(**Note**: If the values in train.dat does not lie in the range **[0, 1]**, it would cause an assertion. Try to add ```--rescale true``` after ```dnn-init``` like: ```dnn-init --rescale true --nodes 1024-1024 train.dat```.)\r\n\r\n### dnn-train\r\n```\r\ndnn-train [options] training_data [model_out]\r\n```\r\nThis program perform mini-batch stochastic gradient descent (mini-batch SGD) to train the model initialized by ```dnn-init```.\r\n```\r\ndnn-train train.dat --pre 2 -f train.dat.model\r\n```\r\n\r\n### dnn-predict\r\n```\r\ndnn-predict testing_data model_in [predict_out]\r\n```\r\nFor example:\r\n```\r\ndnn-predict test.dat train.dat.model\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}